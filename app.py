import streamlit as st
import pandas as pd
import os
import glob
import datetime
import time
import base64
import json
import requests
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# LangChain & AI
from langchain_community.document_loaders import PyPDFLoader
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate
from langchain_core.messages import HumanMessage
from langchain_community.tools import DuckDuckGoSearchRun

# Firebase
import firebase_admin
from firebase_admin import credentials, firestore

# -----------------------------------------------------------------------------
# [0] ì„¤ì • ë° ìƒìˆ˜ ì •ì˜
# -----------------------------------------------------------------------------
st.set_page_config(page_title="KW-ê°•ì˜ë§ˆìŠ¤í„° Pro", page_icon="ğŸ“", layout="wide")

# ê´‘ìš´ëŒ€í•™êµ ì „ì²´ í•™ê³¼ ë¦¬ìŠ¤íŠ¸ (ìƒìˆ˜)
ALL_DEPARTMENTS = [
    "ì „ììœµí•©ê³µí•™ê³¼", "ì „ìê³µí•™ê³¼", "ì „ìí†µì‹ ê³µí•™ê³¼", "ì „ê¸°ê³µí•™ê³¼", "ì „ìì¬ë£Œê³µí•™ê³¼", "ë¡œë´‡í•™ë¶€",
    "ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€", "ì»´í“¨í„°ì •ë³´ê³µí•™ë¶€", "ì •ë³´ìœµí•©í•™ë¶€",
    "ê±´ì¶•í•™ê³¼", "ê±´ì¶•ê³µí•™ê³¼", "í™”í•™ê³µí•™ê³¼", "í™˜ê²½ê³µí•™ê³¼",
    "ìˆ˜í•™ê³¼", "ì „ìë°”ì´ì˜¤ë¬¼ë¦¬í•™ê³¼", "í™”í•™ê³¼", "ìŠ¤í¬ì¸ ìœµí•©ê³¼í•™ê³¼",
    "êµ­ì–´êµ­ë¬¸í•™ê³¼", "ì˜ì–´ì‚°ì—…í•™ê³¼", "ë¯¸ë””ì–´ì»¤ë®¤ë‹ˆì¼€ì´ì…˜í•™ë¶€", "ì‚°ì—…ì‹¬ë¦¬í•™ê³¼", "ë™ë¶ì•„ë¬¸í™”ì‚°ì—…í•™ë¶€",
    "í–‰ì •í•™ê³¼", "ë²•í•™ë¶€", "êµ­ì œí•™ë¶€", "ê²½ì˜í•™ë¶€", "êµ­ì œí†µìƒí•™ë¶€"
]
ALL_DEPARTMENTS.sort()

# [ë³µêµ¬] ìƒì„¸ ì‹œê°„í‘œ ìƒì„± ì§€ì¹¨ (ì •í™•ë„ í–¥ìƒ)
COMMON_TIMETABLE_INSTRUCTION = """
[â˜…â˜…â˜… í•µì‹¬ ì•Œê³ ë¦¬ì¦˜: 3ë‹¨ê³„ ê²€ì¦ ë° í•„í„°ë§ (Strict Verification) â˜…â˜…â˜…]

1. **Step 1: ìš”ëŒ(Curriculum) ê¸°ë°˜ 'ìˆ˜ê°• ëŒ€ìƒ' ë¦¬ìŠ¤íŠ¸ í™•ì •**:
   - ë¨¼ì € PDF ìš”ëŒ ë¬¸ì„œì—ì„œ **'{major} {grade} {semester}'**ì— ë°°ì •ëœ **'í‘œì¤€ ì´ìˆ˜ ê³¼ëª©' ëª©ë¡**ì„ ì¶”ì¶œí•˜ì„¸ìš”.
   - **ì£¼ì˜:** 'MSC í•„ìˆ˜', 'ê³µí•™ì¸ì¦ í•„ìˆ˜'ë¼ê³  ì í˜€ ìˆì–´ë„, ì´ í•™ê¸°(ì˜ˆ: 1í•™ë…„ 1í•™ê¸°) í‘œì— ì—†ìœ¼ë©´ ë¦¬ìŠ¤íŠ¸ì— ë„£ì§€ ë§ˆì„¸ìš”.

2. **Step 2: í•™ë…„ ì •í•©ì„± ê²€ì‚¬ (Grade Validation)**:
   - ì¶”ì¶œëœ ê³¼ëª©ì´ ì‹¤ì œ ì‹œê°„í‘œ ë°ì´í„°ì—ì„œ ëª‡ í•™ë…„ ëŒ€ìƒìœ¼ë¡œ ê°œì„¤ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.
   - **ì‚¬ìš©ìê°€ ì„ íƒí•œ í•™ë…„({grade})ê³¼ ì‹œê°„í‘œì˜ ëŒ€ìƒ í•™ë…„ì´ ì¼ì¹˜í•˜ì§€ ì•Šìœ¼ë©´ ê³¼ê°íˆ ì œì™¸í•˜ì„¸ìš”.**
   - (ì˜ˆ: ì‚¬ìš©ìê°€ 1í•™ë…„ì¸ë°, ì‹œê°„í‘œì— '2í•™ë…„' ëŒ€ìƒì´ë¼ê³  ì í˜€ìˆìœ¼ë©´ ë°°ì¹˜ ê¸ˆì§€)

3. **Step 3: ì‹œê°„í‘œ ë°ì´í„°ì™€ ì •ë°€ ëŒ€ì¡° (Exact Match)**:
   - ìœ„ ë‹¨ê³„ë¥¼ í†µê³¼í•œ ê³¼ëª©ë§Œ ì‹œê°„í‘œì— ë°°ì¹˜í•˜ì„¸ìš”.
   - **ê³¼ëª©ëª… ì™„ì „ ì¼ì¹˜ í•„ìˆ˜**: ì˜ˆ: 'ëŒ€í•™ë¬¼ë¦¬í•™1' vs 'ëŒ€í•™ë¬¼ë¦¬ë°ì‹¤í—˜1' êµ¬ë¶„.

4. **ì¶œë ¥ í˜•ì‹ (ì„¸ë¡œí˜• HTML Table)**:
   - ë°˜ë“œì‹œ **HTML `<table>` íƒœê·¸**ë¥¼ ì‚¬ìš©í•´ë¼.
   - **í–‰(Row): 1êµì‹œ ~ 9êµì‹œ** (í–‰ ë¨¸ë¦¬ê¸€ì— ì‹œê°„ í¬í•¨: 1êµì‹œ (09:00~10:15) ë“±)
   - **ì—´(Column): ì›”, í™”, ìˆ˜, ëª©, ê¸ˆ, í† , ì¼** (7ì¼ ëª¨ë‘ í‘œì‹œ)
   - **ìŠ¤íƒ€ì¼ ê·œì¹™**:
     - `table` íƒœê·¸ì— `width="100%"` ì†ì„±ì„ ì£¼ì–´ë¼.
     - **ê°™ì€ ê³¼ëª©ì€ ë°˜ë“œì‹œ ê°™ì€ ë°°ê²½ìƒ‰**ì„ ì‚¬ìš©í•´ë¼. (íŒŒìŠ¤í…”í†¤ ê¶Œì¥)
     - **ìˆ˜ì—…ì´ ì—†ëŠ” ë¹ˆ ì‹œê°„(ê³µê°•)ì€ ë°˜ë“œì‹œ í°ìƒ‰ ë°°ê²½**ìœ¼ë¡œ ë‘¬ë¼.
     - ì…€ ë‚´ìš©: `<b>ê³¼ëª©ëª…</b><br><small>êµìˆ˜ëª… (ëŒ€ìƒí•™ë…„)</small>`

5. **ì˜¨ë¼ì¸ ë° ì›ê²© ê°•ì˜ ì²˜ë¦¬ (í•„ìˆ˜ - í‘œ ë‚´ë¶€ì— í¬í•¨)**:
   - ê°•ì˜ ì‹œê°„ì´ **'ì˜¨ë¼ì¸', 'ì›ê²©', 'Cyber', 'ì‹œê°„ ë¯¸ì§€ì •'** ë“±ì´ë©´ **ì‹œê°„í‘œ í‘œ(Table)ì˜ ë§¨ ë§ˆì§€ë§‰ í–‰ì— ì¶”ê°€**í•˜ì„¸ìš”.
   - **í–‰ ì œëª©:** `<b>ì˜¨ë¼ì¸/ê¸°íƒ€</b>`
   - **ë‚´ìš©:** í•´ë‹¹ë˜ëŠ” ëª¨ë“  ê³¼ëª©ì„ `<b>ê³¼ëª©ëª…</b>(êµìˆ˜ëª…)` í˜•ì‹ìœ¼ë¡œ ë‚˜ì—´í•˜ì„¸ìš”. (ìš”ì¼ ì—´ì€ í•©ì¹˜ê±°ë‚˜(colspan) ì ì ˆíˆ ë¶„ë°°í•˜ì—¬ í‘œì‹œ)
   - **ì ˆëŒ€ í‘œ ë°–ìœ¼ë¡œ ë¹¼ì§€ ë§ê³ , í…Œì´ë¸”ì˜ ì¼ë¶€ë¡œ í¬í•¨ì‹œí‚¤ì„¸ìš”.**

6. **ì¶œë ¥ ìˆœì„œ ê³ ì •**:
   - 1ìˆœìœ„: HTML ì‹œê°„í‘œ í‘œ (ì˜¨ë¼ì¸ ê°•ì˜ í¬í•¨)
   - 2ìˆœìœ„: "### âœ… í•„ìˆ˜ ê³¼ëª© ê²€ì¦ ë° í•™ë…„ ì¼ì¹˜ í™•ì¸" (ê° ê³¼ëª©ë³„ë¡œ 'ëŒ€ìƒ í•™ë…„'ì´ ë§ëŠ”ì§€ ëª…ì‹œ)
   - 3ìˆœìœ„: "### âš ï¸ ë°°ì¹˜ ì‹¤íŒ¨/ì œì™¸ ëª©ë¡" (í•™ë…„ ë¶ˆì¼ì¹˜ë¡œ ì œì™¸ëœ ê³¼ëª© í¬í•¨)
"""

# CSS ìŠ¤íƒ€ì¼
st.markdown("""
    <style>
        footer { visibility: hidden; }
        div.row-widget.stRadio > div { flex-direction: row; align-items: stretch; }
        div.row-widget.stRadio > div[role="radiogroup"] > label {
            background-color: #f0f2f6; padding: 10px 20px; border-radius: 10px; margin-right: 10px; border: 1px solid #e0e0e0; cursor: pointer; transition: all 0.3s;
        }
        div.row-widget.stRadio > div[role="radiogroup"] > label[data-checked="true"] {
            background-color: #ff4b4b; color: white; border-color: #ff4b4b;
        }
        .stTabs [data-baseweb="tab-list"] { gap: 10px; }
        .stTabs [data-baseweb="tab"] { height: 40px; white-space: pre-wrap; border-radius: 4px; gap: 1px; padding-top: 5px; padding-bottom: 5px; }
        @media only screen and (max-width: 600px) {
            .main .block-container { padding-top: 2rem !important; }
            div[data-testid="stMarkdownContainer"] table { font-size: 10px !important; }
        }
    </style>
""", unsafe_allow_html=True)

# API Key ë¡œë“œ
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = os.environ.get("GOOGLE_API_KEY", "")

if not api_key:
    st.error("ğŸš¨ **Google API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.**")
    st.stop()

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if "user" not in st.session_state: st.session_state.user = None
if "global_log" not in st.session_state: st.session_state.global_log = []
if "shared_context" not in st.session_state: st.session_state.shared_context = "" 
if "grade_json_data" not in st.session_state: st.session_state.grade_json_data = None
if "graduation_json_data" not in st.session_state: st.session_state.graduation_json_data = None 
if "graduation_analysis_result" not in st.session_state: st.session_state.graduation_analysis_result = "" # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ìš©
if "timetable_result" not in st.session_state: st.session_state.timetable_result = ""
if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "timetable_chat_history" not in st.session_state: st.session_state.timetable_chat_history = []
if "graduation_chat_history" not in st.session_state: st.session_state.graduation_chat_history = []
if "bookmarks" not in st.session_state: st.session_state.bookmarks = [] 
if "current_menu" not in st.session_state: st.session_state.current_menu = "ğŸ“ˆ ì„±ì  ë° ì§„ë¡œ ì§„ë‹¨"

# -----------------------------------------------------------------------------
# [Firebase Manager]
# -----------------------------------------------------------------------------
class FirebaseManager:
    def __init__(self):
        self.db = None
        self.is_initialized = False
        self.init_firestore()

    def init_firestore(self):
        if "firebase_service_account" in st.secrets:
            try:
                if not firebase_admin._apps:
                    cred_info = dict(st.secrets["firebase_service_account"])
                    cred = credentials.Certificate(cred_info)
                    firebase_admin.initialize_app(cred)
                self.db = firestore.client()
                self.is_initialized = True
            except Exception: pass

    def auth_user(self, email, password, mode="login"):
        if "FIREBASE_WEB_API_KEY" not in st.secrets: return None, "API Key ì„¤ì • í•„ìš”"
        api_key_fb = st.secrets["FIREBASE_WEB_API_KEY"].strip()
        endpoint = "signInWithPassword" if mode == "login" else "signUp"
        url = f"https://identitytoolkit.googleapis.com/v1/accounts:{endpoint}?key={api_key_fb}"
        payload = {"email": email, "password": password, "returnSecureToken": True}
        try:
            res = requests.post(url, json=payload)
            data = res.json()
            if "error" in data: return None, data["error"]["message"]
            return data, None
        except Exception as e: return None, str(e)

    def save_user_data(self, collection, doc_id, data):
        if not self.is_initialized or not st.session_state.user: return False
        try:
            user_id = st.session_state.user['localId']
            data['updated_at'] = firestore.SERVER_TIMESTAMP
            self.db.collection('users').document(user_id).collection(collection).document(doc_id).set(data)
            return True
        except: return False
    
    def load_user_data(self, collection, doc_id):
        if not self.is_initialized or not st.session_state.user: return None
        try:
            user_id = st.session_state.user['localId']
            doc = self.db.collection('users').document(user_id).collection(collection).document(doc_id).get()
            return doc.to_dict() if doc.exists else None
        except: return None

    def add_bookmark(self, question, answer, tag):
        if not self.is_initialized or not st.session_state.user: return False
        try:
            user_id = st.session_state.user['localId']
            data = {"question": question, "answer": answer, "tag": tag, "created_at": firestore.SERVER_TIMESTAMP}
            self.db.collection('users').document(user_id).collection('bookmarks').add(data)
            return True
        except: return False

    def load_bookmarks(self):
        if not self.is_initialized or not st.session_state.user: return []
        try:
            user_id = st.session_state.user['localId']
            docs = self.db.collection('users').document(user_id).collection('bookmarks').order_by('created_at', direction=firestore.Query.DESCENDING).stream()
            return [{"id": doc.id, **doc.to_dict()} for doc in docs]
        except: return []

fb_manager = FirebaseManager()

# -----------------------------------------------------------------------------
# [AI ì—”ì§„] - ëª¨ë¸ëª… ìˆ˜ì • (gemini-1.5-flash)
# -----------------------------------------------------------------------------
def get_llm(): 
    return ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0, google_api_key=api_key)

def get_pro_llm(): 
    return ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0, google_api_key=api_key)

@st.cache_resource
def load_knowledge_base():
    if not os.path.exists("data"): return ""
    pdf_files = glob.glob("data/*.pdf")
    content = ""
    for f in pdf_files:
        try: content += f"\n\n--- [{os.path.basename(f)}] ---\n" + "".join([p.page_content for p in PyPDFLoader(f).load()])
        except: pass
    return content

PRE_LEARNED_DATA = load_knowledge_base()

def clean_json_output(text):
    text = text.strip()
    if text.startswith("```json"): 
        text = text[7:]
    elif text.startswith("```"): 
        text = text[3:]
    if text.endswith("```"): 
        text = text[:-3]
    return text.strip()

def clean_html_output(text):
    cleaned = text.strip()
    if cleaned.startswith("```html"):
        cleaned = cleaned[7:]
    elif cleaned.startswith("```"):
        cleaned = cleaned[3:]
    if cleaned.endswith("```"):
        cleaned = cleaned[:-3]
    return cleaned.replace("```html", "").replace("```", "").strip()

# -----------------------------------------------------------------------------
# [ê¸°ëŠ¥ 1] ì„±ì í‘œ ë¶„ì„ (JSON)
# -----------------------------------------------------------------------------
def analyze_grades_structure(uploaded_images):
    llm = get_pro_llm()
    image_messages = []
    for img_file in uploaded_images:
        img_file.seek(0)
        b64 = base64.b64encode(img_file.read()).decode("utf-8")
        image_messages.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})
    
    prompt = """
    ì„±ì í‘œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ **ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹**ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€.
    {
        "student_info": {"admission_year": "2024", "major": "ì „ìê³µí•™ê³¼"},
        "courses": [{"year": "2024", "semester": "1", "type": "ì „í•„", "name": "íšŒë¡œì´ë¡ 1", "grade": "A+", "score": 4.5}, ...],
        "strength_keywords": ["íšŒë¡œì„¤ê³„", "ì„ë² ë””ë“œ"],
        "weakness_analysis": "ì „ê³µ ê¸°ì´ˆëŠ” íŠ¼íŠ¼í•˜ë‚˜ SW ê´€ë ¨ í”„ë¡œì íŠ¸ ê²½í—˜ì´ ë¶€ì¡±í•¨."
    }
    """
    msg = HumanMessage(content=[{"type": "text", "text": prompt}] + image_messages)
    try:
        res = llm.invoke([msg]).content
        return json.loads(clean_json_output(res))
    except: return None

# -----------------------------------------------------------------------------
# [ê¸°ëŠ¥ 2] ì¡¸ì—… ìš”ê±´ ë¶„ì„ (JSON + ë¦¬í¬íŠ¸ + ìƒë‹´)
# -----------------------------------------------------------------------------
def analyze_graduation_json(uploaded_images):
    llm = get_pro_llm()
    image_messages = []
    for img_file in uploaded_images:
        img_file.seek(0)
        b64 = base64.b64encode(img_file.read()).decode("utf-8")
        image_messages.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{b64}"}})
    
    prompt = """
    ì¡¸ì—… ìš”ê±´ì„ ì§„ë‹¨í•˜ì—¬ **JSON ë°ì´í„°**ì™€ **ë¶„ì„ ë¦¬í¬íŠ¸(Text)** ë‘ ê°€ì§€ë¥¼ ëª¨ë‘ í¬í•¨í•œ JSONìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”.
    [í•™ì‚¬ ë¬¸ì„œ]ë¥¼ ì°¸ê³ í•˜ì—¬ ì •í™•íˆ ê³„ì‚°í•˜ì„¸ìš”.
    ì¶œë ¥ í˜•ì‹:
    {
        "chart_data": {
            "total": {"earned": 100, "required": 130},
            "major_req": {"earned": 15, "required": 21},
            "major_sel": {"earned": 30, "required": 54},
            "liberal": {"earned": 20, "required": 30}
        },
        "report_text": "### ğŸ“ ì¡¸ì—… ìš”ê±´ ì§„ë‹¨ ê²°ê³¼\n\n..."
    }
    """
    msg = HumanMessage(content=[{"type": "text", "text": prompt}] + image_messages + [{"type": "text", "text": f"\n[í•™ì‚¬ ë¬¸ì„œ]\n{PRE_LEARNED_DATA}"}])
    try:
        res = llm.invoke([msg]).content
        return json.loads(clean_json_output(res))
    except: return None

# [ë³µêµ¬] ì¡¸ì—… ìš”ê±´ ìƒë‹´ í•¨ìˆ˜
def chat_with_graduation_ai(current_analysis, user_input):
    llm = get_llm()
    template = """
    ë‹¹ì‹ ì€ í•™ì‚¬ ì „ë¬¸ AI ìƒë‹´ì‚¬ì…ë‹ˆë‹¤.
    [í˜„ì¬ ì§„ë‹¨ ê²°ê³¼] {current_analysis}
    [ì‚¬ìš©ì ì…ë ¥] "{user_input}"
    
    ì§€ì‹œì‚¬í•­:
    1. ì‚¬ìš©ìê°€ ì •ë³´ë¥¼ ìˆ˜ì •/ì¶”ê°€(ì˜ˆ: "ë‚˜ ìº¡ìŠ¤í†¤ ë“¤ì—ˆì–´")í•˜ë©´, ì§„ë‹¨ ê²°ê³¼ë¥¼ ìˆ˜ì •í•´ì„œ ë‹¤ì‹œ ì‘ì„±í•˜ê³  ë§¨ ì•ì— **[ìˆ˜ì •]** íƒœê·¸ë¥¼ ë¶™ì´ì„¸ìš”.
    2. ë‹¨ìˆœ ì§ˆë¬¸(ì˜ˆ: "MSCê°€ ë­ì•¼?")ì´ë©´ ì¹œì ˆí•˜ê²Œ ë‹µë³€ë§Œ í•˜ì„¸ìš”.
    
    [ì°¸ê³  ë¬¸í—Œ] {context}
    """
    prompt = PromptTemplate(template=template, input_variables=["current_analysis", "user_input", "context"])
    return (prompt | llm).invoke({"current_analysis": current_analysis, "user_input": user_input, "context": PRE_LEARNED_DATA}).content

# -----------------------------------------------------------------------------
# [ê¸°ëŠ¥ 3] AI ë„êµ¬ (ì»¤ë¦¬ì–´, ì‹œê°„í‘œ)
# -----------------------------------------------------------------------------
def consult_career_path(job_role, grade_json, context):
    llm = get_llm()
    search = DuckDuckGoSearchRun()
    try: search_res = search.invoke(f"{job_role} ì‹ ì… ì±„ìš© ê¸°ìˆ  ìŠ¤íƒ ìê²©ìš”ê±´")
    except: search_res = "ê²€ìƒ‰ ë¶ˆê°€"
    
    template = """
    ë‹¹ì‹ ì€ ëƒ‰ì² í•œ ì±„ìš© ë‹´ë‹¹ìì…ë‹ˆë‹¤.
    [ì§€ì›ì ìŠ¤í™] {student_data}
    [ì‹œì¥ ìš”êµ¬ì‚¬í•­] {search_result}
    [í•™êµ ì»¤ë¦¬í˜ëŸ¼] {context}
    ì§€ì›ìì˜ ë¶€ì¡±í•œ ì (Skill Gap)ì„ ì§€ì í•˜ê³ , í•™êµ ê°•ì˜ ì¤‘ ë¬´ì—‡ì„ ë“¤ì–´ì•¼ í• ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì¶”ì²œí•˜ì„¸ìš”.
    """
    prompt = PromptTemplate(template=template, input_variables=["student_data", "search_result", "context"])
    return (prompt | llm).invoke({"student_data": json.dumps(grade_json), "search_result": search_res, "context": context}).content

# [ë³µêµ¬] ìƒì„¸ í”„ë¡¬í”„íŠ¸ ì ìš©ëœ ì‹œê°„í‘œ ìƒì„±
def generate_timetable_ai(major, grade, semester, target, blocked, req, shared_ctx):
    llm = get_llm()
    template = """
    ìˆ˜ê°•ì‹ ì²­ ì „ë¬¸ê°€ë¡œì„œ ì‹œê°„í‘œë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    [í•™ìƒ ì •ë³´] {major} {grade} {semester}, ëª©í‘œ {target}í•™ì 
    [ê³µê°• ì‹œê°„] {blocked}
    [ì¶”ê°€ ìš”êµ¬] {req}
    
    â˜…â˜…â˜… [ì´ì „ ìƒë‹´ ë§¥ë½ ë°˜ì˜] â˜…â˜…â˜…
    "{shared_ctx}"
    
    """ + COMMON_TIMETABLE_INSTRUCTION + """
    
    [í•™ìŠµ ë¬¸ì„œ] {context}
    """
    prompt = PromptTemplate(template=template, input_variables=["major", "grade", "semester", "target", "blocked", "req", "shared_ctx", "context"])
    res = (prompt | llm).invoke({
        "major": major, "grade": grade, "semester": semester, "target": target, 
        "blocked": blocked, "req": req, "shared_ctx": shared_ctx, "context": PRE_LEARNED_DATA
    }).content
    return clean_html_output(res)

# [ë³µêµ¬] ì‹œê°„í‘œ ìƒë‹´ í•¨ìˆ˜
def chat_with_timetable_ai(current_timetable, user_input, major, grade, semester):
    llm = get_llm()
    template = """
    ì‹œê°„í‘œ ìƒë‹´ AIì…ë‹ˆë‹¤.
    [í˜„ì¬ ì‹œê°„í‘œ] {current_timetable}
    [ì‚¬ìš©ì ì…ë ¥] "{user_input}"
    [í•™ìƒ ì •ë³´] {major} {grade} {semester}
    
    ì§€ì‹œì‚¬í•­:
    1. ì‹œê°„í‘œ ìˆ˜ì • ìš”ì²­ì´ë©´ **[ìˆ˜ì •]** íƒœê·¸ë¥¼ ë¶™ì´ê³  HTML Tableì„ ë‹¤ì‹œ ì‘ì„±í•˜ì„¸ìš”.
    """ + COMMON_TIMETABLE_INSTRUCTION + """
    2. ë‹¨ìˆœ ì§ˆë¬¸ì´ë©´ ë‹µë³€ë§Œ í•˜ì„¸ìš”.
    
    [í•™ìŠµ ë¬¸ì„œ] {context}
    """
    prompt = PromptTemplate(template=template, input_variables=["current_timetable", "user_input", "major", "grade", "semester", "context"])
    res = (prompt | llm).invoke({
        "current_timetable": current_timetable, "user_input": user_input, 
        "major": major, "grade": grade, "semester": semester, "context": PRE_LEARNED_DATA
    }).content
    return res

# -----------------------------------------------------------------------------
# [UI] ë©”ì¸ ì•±
# -----------------------------------------------------------------------------
with st.sidebar:
    st.title("ğŸ—‚ï¸ ë‚´ë¹„ê²Œì´ì…˜")
    
    if st.session_state.user is None:
        with st.expander("ğŸ” ë¡œê·¸ì¸ / íšŒì›ê°€ì…", expanded=True):
            mode = st.radio("ëª¨ë“œ", ["ë¡œê·¸ì¸", "íšŒì›ê°€ì…"], horizontal=True, label_visibility="collapsed")
            email = st.text_input("ì´ë©”ì¼")
            pw = st.text_input("ë¹„ë°€ë²ˆí˜¸", type="password")
            if st.button("ì‹¤í–‰"):
                u, e = fb_manager.auth_user(email, pw, "login" if mode == "ë¡œê·¸ì¸" else "signup")
                if u:
                    st.session_state.user = u
                    # ë°ì´í„° ë¡œë“œ
                    grade_data = fb_manager.load_user_data('grade_data', 'latest')
                    if grade_data: st.session_state.grade_json_data = grade_data
                    
                    grad_data = fb_manager.load_user_data('graduation_data', 'latest')
                    if grad_data: 
                        st.session_state.graduation_json_data = grad_data
                        if 'report_text' in grad_data: st.session_state.graduation_analysis_result = grad_data['report_text']
                    
                    st.success("ë¡œê·¸ì¸ ì„±ê³µ!")
                    time.sleep(1)
                    st.rerun()
                else: st.error(e)
    else:
        st.info(f"ğŸ‘‹ {st.session_state.user['email']}ë‹˜")
        if st.button("ë¡œê·¸ì•„ì›ƒ"):
            st.session_state.user = None
            st.session_state.grade_json_data = None
            st.session_state.graduation_json_data = None
            st.session_state.graduation_analysis_result = ""
            st.rerun()

    if st.session_state.user:
        st.divider()
        st.subheader("ğŸ“‚ Q&A ë³´ê´€í•¨")
        bookmarks = fb_manager.load_bookmarks()
        if not bookmarks: st.caption("ì €ì¥ëœ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
        for bm in bookmarks:
            with st.expander(f"ğŸ“Œ {bm['question'][:15]}..."):
                st.write(f"**Q:** {bm['question']}")
                st.write(f"**A:** {bm['answer']}")
                st.caption(f"Tag: {bm['tag']}")

# ë©”ì¸ í˜ì´ì§€
st.title("ğŸ“ KW-ê°•ì˜ë§ˆìŠ¤í„° Pro")
menu_options = ["ğŸ“ˆ ì„±ì  ë° ì§„ë¡œ ì§„ë‹¨", "ğŸ“… ìŠ¤ë§ˆíŠ¸ ì‹œê°„í‘œ", "ğŸ¤– AI í•™ì‚¬ ì§€ì‹ì¸"]
menu = st.radio("ê¸°ëŠ¥ ì„ íƒ", menu_options, horizontal=True, label_visibility="collapsed")

# -----------------------------------------------------------------------------
# MENU 1: ì„±ì  ë° ì§„ë¡œ ì§„ë‹¨
# -----------------------------------------------------------------------------
if menu == "ğŸ“ˆ ì„±ì  ë° ì§„ë¡œ ì§„ë‹¨":
    st.header("ğŸ“ˆ ì„±ì  ë¶„ì„ ë° ì§„ë¡œ ì„¤ê³„")
    sub_tabs = st.tabs(["ğŸ“Š ì„±ì  ë¶„ì„", "ğŸ“ ì¡¸ì—… ìš”ê±´ í™•ì¸", "ğŸš€ AI ì»¤ë¦¬ì–´ ì†”ë£¨ì…˜"])
    
    # 1. ì„±ì  ë¶„ì„
    with sub_tabs[0]:
        st.markdown("##### ğŸ“„ ì„±ì í‘œ ì—…ë¡œë“œ")
        uploaded_grades = st.file_uploader("ì„±ì í‘œ ì´ë¯¸ì§€", accept_multiple_files=True, key="grade_upl")
        if uploaded_grades and st.button("ë¶„ì„ ì‹œì‘", key="anlz_btn"):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                data = analyze_grades_structure(uploaded_grades)
                if data:
                    st.session_state.grade_json_data = data
                    if "weakness_analysis" in data: st.session_state.shared_context = data["weakness_analysis"]
                    fb_manager.save_user_data('grade_data', 'latest', data)
                    st.rerun()

        if st.session_state.grade_json_data:
            d = st.session_state.grade_json_data
            st.success(f"í•™ë²ˆ: {d.get('student_info',{}).get('admission_year')} | ì „ê³µ: {d.get('student_info',{}).get('major')}")
            if st.session_state.shared_context: st.info(f"ğŸ’¡ **AI ì§„ë‹¨(ë§¥ë½):** {st.session_state.shared_context}")
            st.write("ğŸ”¥ **ë‚˜ì˜ ê°•ì :** " + " ".join([f"`{k}`" for k in d.get("strength_keywords", [])]))
            df = pd.DataFrame(d.get("courses", []))
            if not df.empty:
                df['score'] = pd.to_numeric(df['score'], errors='coerce')
                st.line_chart(df.groupby('year')['score'].mean())
                with st.expander("ë°ì´í„° ì›ë³¸"): st.json(d)

    # 2. ì¡¸ì—… ìš”ê±´ (ë„ë„› ì°¨íŠ¸ + ìƒë‹´ ë³µêµ¬)
    with sub_tabs[1]:
        st.markdown("##### ğŸ“ ì¡¸ì—… ìš”ê±´ ë‹¬ì„±ë¥ ")
        grad_files = st.file_uploader("ì¡¸ì—… ìš”ê±´ìš© ì„±ì í‘œ", accept_multiple_files=True, key="grad_upl")
        if grad_files and st.button("ì¡¸ì—… ìš”ê±´ ì§„ë‹¨", key="grad_btn"):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                res = analyze_graduation_json(grad_files)
                if res:
                    st.session_state.graduation_json_data = res
                    st.session_state.graduation_analysis_result = res.get("report_text", "")
                    st.session_state.graduation_chat_history = []
                    fb_manager.save_user_data('graduation_data', 'latest', res)
                    st.rerun()
        
        # ì°¨íŠ¸ í‘œì‹œ
        if st.session_state.graduation_json_data:
            data = st.session_state.graduation_json_data.get("chart_data", {})
            if data:
                fig = make_subplots(rows=1, cols=4, specs=[[{'type':'domain'}]*4], 
                                    subplot_titles=['ì´ í•™ì ', 'ì „ê³µ í•„ìˆ˜', 'ì „ê³µ ì„ íƒ', 'êµì–‘'])
                keys = ['total', 'major_req', 'major_sel', 'liberal']
                for i, key in enumerate(keys):
                    curr = data.get(key, {}).get('earned', 0)
                    req = data.get(key, {}).get('required', 100)
                    fig.add_trace(go.Pie(labels=["ì´ìˆ˜", "ë¯¸ì´ìˆ˜"], values=[curr, max(0, req-curr)], hole=.6, marker_colors=['#4CAF50', '#E0E0E0'], textinfo='none'), 1, i+1)
                    fig.add_annotation(text=f"<b>{int((curr/req)*100 if req>0 else 0)}%</b>", x=[0.11, 0.37, 0.63, 0.89][i], y=0.5, showarrow=False, font_size=20)
                fig.update_layout(height=250, margin=dict(t=30, b=0, l=0, r=0), showlegend=False)
                st.plotly_chart(fig, use_container_width=True)

        # ë¦¬í¬íŠ¸ ë° ìƒë‹´
        if st.session_state.graduation_analysis_result:
            st.markdown(st.session_state.graduation_analysis_result)
            st.divider()
            st.subheader("ğŸ’¬ ì¡¸ì—… ìš”ê±´ ìƒë‹´ì†Œ")
            for msg in st.session_state.graduation_chat_history:
                with st.chat_message(msg["role"]): st.markdown(msg["content"])
            
            if chat_input := st.chat_input("ì˜ˆ: ìº¡ìŠ¤í†¤ë””ìì¸ ë“¤ì—ˆëŠ”ë° ì™œ ë¯¸ì´ìˆ˜ì•¼?", key="grad_chat"):
                st.session_state.graduation_chat_history.append({"role": "user", "content": chat_input})
                with st.chat_message("user"): st.write(chat_input)
                with st.chat_message("assistant"):
                    with st.spinner("ë¶„ì„ ì¤‘..."):
                        resp = chat_with_graduation_ai(st.session_state.graduation_analysis_result, chat_input)
                        if "[ìˆ˜ì •]" in resp:
                            new_res = resp.replace("[ìˆ˜ì •]", "").strip()
                            st.session_state.graduation_analysis_result = new_res
                            st.write("ë¦¬í¬íŠ¸ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤. ìœ„ ë‚´ìš©ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
                            st.session_state.graduation_chat_history.append({"role": "assistant", "content": "ë¦¬í¬íŠ¸ ìˆ˜ì • ì™„ë£Œ."})
                            st.rerun()
                        else:
                            st.markdown(resp)
                            st.session_state.graduation_chat_history.append({"role": "assistant", "content": resp})

    # 3. ì»¤ë¦¬ì–´
    with sub_tabs[2]:
        st.markdown("##### ğŸš€ AI ì±„ìš© ë‹´ë‹¹ì ì»¨ì„¤íŒ…")
        job = st.text_input("í¬ë§ ì§ë¬´")
        if st.button("ë¶„ì„"):
            if not st.session_state.grade_json_data: st.error("ì„±ì  ë¶„ì„ ë¨¼ì € ì§„í–‰í•˜ì„¸ìš”.")
            else:
                with st.spinner("ê²€ìƒ‰ ë° ë¶„ì„ ì¤‘..."):
                    res = consult_career_path(job, st.session_state.grade_json_data, PRE_LEARNED_DATA)
                    st.markdown(res)
                    st.session_state.shared_context += f"\n(ì§„ë¡œ ì¡°ì–¸: {job} ê´€ë ¨ ì—­ëŸ‰ ë³´ê°• í•„ìš”)"

# -----------------------------------------------------------------------------
# MENU 2: ìŠ¤ë§ˆíŠ¸ ì‹œê°„í‘œ (ìƒì„¸ í”„ë¡¬í”„íŠ¸ + ìƒë‹´ ë³µêµ¬)
# -----------------------------------------------------------------------------
elif menu == "ğŸ“… ìŠ¤ë§ˆíŠ¸ ì‹œê°„í‘œ":
    st.header("ğŸ“… ë§¥ë½ ê¸°ë°˜ AI ì‹œê°„í‘œ")
    if st.session_state.shared_context: st.info(f"ğŸ’¡ **ë°˜ì˜ëœ ë§¥ë½:** {st.session_state.shared_context}")
    
    col1, col2 = st.columns([1, 2])
    with col1:
        major = st.selectbox("í•™ê³¼ ì„ íƒ", ALL_DEPARTMENTS)
        grade = st.selectbox("í•™ë…„", ["1í•™ë…„", "2í•™ë…„", "3í•™ë…„", "4í•™ë…„"])
        semester = st.selectbox("í•™ê¸°", ["1í•™ê¸°", "2í•™ê¸°"])
        target = st.number_input("ëª©í‘œ í•™ì ", 9, 24, 18)
        req = st.text_area("ì¶”ê°€ ìš”êµ¬ì‚¬í•­")
    with col2:
        st.caption("ê³µê°• ì‹œê°„ ì„ íƒ (ì²´í¬ í•´ì œ ì‹œ ê³µê°•)")
        times = ["1êµì‹œ", "2êµì‹œ", "3êµì‹œ", "4êµì‹œ", "5êµì‹œ", "6êµì‹œ", "7êµì‹œ", "8êµì‹œ", "9êµì‹œ"]
        if "sched_df" not in st.session_state:
            st.session_state.sched_df = pd.DataFrame(True, index=times, columns=["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ"])
        edited_df = st.data_editor(st.session_state.sched_df, height=300, use_container_width=True)

    if st.button("ì‹œê°„í‘œ ìƒì„±", type="primary"):
        blocked = [f"{d} {t}" for d in edited_df.columns for t in times if not edited_df.loc[t, d]]
        with st.spinner("AIê°€ ì‹œê°„í‘œ ì‘ì„± ì¤‘..."):
            res = generate_timetable_ai(major, grade, semester, target, ", ".join(blocked), req, st.session_state.shared_context)
            st.session_state.timetable_result = res
            st.rerun()

    if st.session_state.timetable_result:
        st.markdown(st.session_state.timetable_result, unsafe_allow_html=True)
        st.divider()
        st.subheader("ğŸ’¬ ì‹œê°„í‘œ ìƒë‹´ì†Œ")
        for msg in st.session_state.timetable_chat_history:
            with st.chat_message(msg["role"]): st.markdown(msg["content"], unsafe_allow_html=True)
        
        if chat_input := st.chat_input("ì˜ˆ: 1êµì‹œ ë¹¼ì¤˜"):
            st.session_state.timetable_chat_history.append({"role": "user", "content": chat_input})
            with st.chat_message("user"): st.write(chat_input)
            with st.chat_message("assistant"):
                with st.spinner("ìˆ˜ì • ì¤‘..."):
                    resp = chat_with_timetable_ai(st.session_state.timetable_result, chat_input, major, grade, semester)
                    if "[ìˆ˜ì •]" in resp:
                        new_tt = clean_html_output(resp.replace("[ìˆ˜ì •]", ""))
                        st.session_state.timetable_result = new_tt
                        st.write("ì‹œê°„í‘œë¥¼ ì—…ë°ì´íŠ¸í–ˆìŠµë‹ˆë‹¤.")
                        st.session_state.timetable_chat_history.append({"role": "assistant", "content": "ìˆ˜ì • ì™„ë£Œ."})
                        st.rerun()
                    else:
                        st.markdown(resp)
                        st.session_state.timetable_chat_history.append({"role": "assistant", "content": resp})

# -----------------------------------------------------------------------------
# MENU 3: AI í•™ì‚¬ ì§€ì‹ì¸ (ë³´ê´€í•¨ ê¸°ëŠ¥)
# -----------------------------------------------------------------------------
elif menu == "ğŸ¤– AI í•™ì‚¬ ì§€ì‹ì¸":
    st.subheader("ğŸ¤– ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”")
    for i, msg in enumerate(st.session_state.chat_history):
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])
            if msg["role"] == "assistant" and i > 0 and st.session_state.chat_history[i-1]["role"] == "user":
                if st.button("ğŸ’¾ ë³´ê´€í•¨ ì €ì¥", key=f"save_{i}"):
                    if fb_manager.add_bookmark(st.session_state.chat_history[i-1]["content"], msg["content"], "ì§€ì‹ì¸"):
                        st.toast("ì €ì¥ ì™„ë£Œ!", icon="âœ…")
                    else: st.toast("ë¡œê·¸ì¸ í•„ìš”", icon="âš ï¸")

    if user_input := st.chat_input("ì§ˆë¬¸ ì…ë ¥"):
        st.session_state.chat_history.append({"role": "user", "content": user_input})
        with st.chat_message("user"): st.markdown(user_input)
        with st.chat_message("assistant"):
            with st.spinner("ìƒì„± ì¤‘..."):
                q_ctx = user_input
                if st.session_state.shared_context: q_ctx = f"[ìƒí™©: {st.session_state.shared_context}] \n{user_input}"
                chain = PromptTemplate.from_template("ë¬¸ì„œ: {ctx}\nì§ˆë¬¸: {q}") | get_llm()
                response = chain.invoke({"ctx": PRE_LEARNED_DATA, "q": q_ctx}).content
                st.markdown(response)
        st.session_state.chat_history.append({"role": "assistant", "content": response})
        st.rerun()
